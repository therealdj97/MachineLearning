{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN works on the principle of saving of a particular layer and feeding this back to the input in order\n",
    "to predict the output of the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The nodes in different layers of NN  are compressed to form a single layer of recurrent NN\n",
    "A, B, C = Parameters of ntwk\n",
    "x = input layer\n",
    "h = hidden layer\n",
    "y = o/p layer\n",
    "x(t) and x(t-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle sequential data, accept the current input data abdpreviously receuved inputs\n",
    "RNNs could memorize previous inputs due to their internal memory\n",
    "Image captioning, time series prediction, NLP, Machine translation, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Types of RNN:\n",
    "    One to One\n",
    "    One to Many\n",
    "    Many to One\n",
    "    Many to Many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Issues with RNN:\n",
    "    Vanishing gradient problem\n",
    "    Exploding gradient problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "16db9e81-fe38-44f0-8a4f-3dba9eba0409",
    "_uuid": "d0469858bd9b00ece464f6267cfad7dc450d5d54"
   },
   "source": [
    "## INTRODUCTION\n",
    "- Itâ€™s a Python based scientific computing package targeted at two sets of audiences:\n",
    "    - A replacement for NumPy to use the power of GPUs\n",
    "    - Deep learning research platform that provides maximum flexibility and speed\n",
    "- pros: \n",
    "    - Iinteractively debugging PyTorch. Many users who have used both frameworks would argue that makes pytorch significantly easier to debug and visualize.\n",
    "    - Clean support for dynamic graphs\n",
    "    - Organizational backing from Facebook\n",
    "    - Blend of high level and low level APIs\n",
    "- cons:\n",
    "    - Much less mature than alternatives\n",
    "    - Limited references / resources outside of the official documentation\n",
    "- I accept you know neural network basics. If you do not know check my tutorial. Because I will not explain neural network concepts detailed, I only explain how to use pytorch for neural network\n",
    "- Neural Network tutorial: https://www.kaggle.com/kanncaa1/deep-learning-tutorial-for-beginners \n",
    "- The most important parts of this tutorial from matrices to ANN. If you learn these parts very well, implementing remaining parts like CNN or RNN will be very easy. \n",
    "<br>\n",
    "<br>**Content:**\n",
    "1. Basics of Pytorch, Linear Regression, Logistic Regression, Artificial Neural Network (ANN), Concolutional Neural Network (CNN)\n",
    "    - https://www.kaggle.com/kanncaa1/pytorch-tutorial-for-deep-learning-lovers/code\n",
    "1. [Recurrent Neural Network (RNN)](#1)\n",
    "1. Long-Short Term Memory (LSTM)\n",
    "    - https://www.kaggle.com/kanncaa1/long-short-term-memory-with-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "### Recurrent Neural Network (RNN)\n",
    "- RNN is essentially repeating ANN but information get pass through from previous non-linear activation function output.\n",
    "- **Steps of RNN:**\n",
    "    1. Import Libraries\n",
    "    1. Prepare Dataset\n",
    "    1. Create RNN Model\n",
    "        - hidden layer dimension is 100\n",
    "        - number of hidden layer is 1 \n",
    "    1. Instantiate Model\n",
    "    1. Instantiate Loss\n",
    "        - Cross entropy loss\n",
    "        - It also has softmax(logistic function) in it.\n",
    "    1. Instantiate Optimizer\n",
    "        - SGD Optimizer\n",
    "    1. Traning the Model\n",
    "    1. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "#print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "55dd8ffd-6011-49a3-a1fe-c6933c4187b7",
    "_uuid": "840f7b1c60d1a2d5b2222a7c53b2b9d08aac9169"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare Dataset\n",
    "# load data\n",
    "#!pip install torchvision \n",
    "import torch\n",
    "import torchvision\n",
    "from sklearn.model_selection import train_test_split\n",
    "train = pd.read_csv(r\"C://Users//DEEPIKA//Documents//Deep Learning//RNN Using PyTorch//train.csv//train.csv\",dtype = np.float32)\n",
    "\n",
    "# split data into features(pixels) and labels(numbers from 0 to 9)\n",
    "targets_numpy = train.label.values\n",
    "features_numpy = train.loc[:,train.columns != \"label\"].values/255 # normalization\n",
    "\n",
    "# train test split. Size of train data is 80% and size of test data is 20%. \n",
    "features_train, features_test, targets_train, targets_test = train_test_split(features_numpy,\n",
    "                                                                             targets_numpy,\n",
    "                                                                             test_size = 0.2,\n",
    "                                                                             random_state = 42) \n",
    "\n",
    "# create feature and targets tensor for train set. As you remember we need variable to accumulate gradients. Therefore first we create tensor, then we will create variable\n",
    "featuresTrain = torch.from_numpy(features_train)\n",
    "targetsTrain = torch.from_numpy(targets_train).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# create feature and targets tensor for test set.\n",
    "featuresTest = torch.from_numpy(features_test)\n",
    "targetsTest = torch.from_numpy(targets_test).type(torch.LongTensor) # data type is long\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 10000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = TensorDataset(featuresTrain,targetsTrain)\n",
    "test = TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "\n",
    "# visualize one of the images in data set\n",
    "plt.imshow(features_numpy[10].reshape(28,28))\n",
    "plt.axis(\"off\")\n",
    "plt.title(str(targets_numpy[10]))\n",
    "plt.savefig('C://Users//DEEPIKA//Documents//Deep Learning//RNN Using PyTorch//graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "482946c2-72d8-4489-a094-d6cb8993a912",
    "_uuid": "ceffbb7fe5381f0d2f5f234ea37d1f834843edee"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "7fbe419e-7ce2-4d72-bb31-8b27e8161f1b",
    "_uuid": "bb1b6d4fb5504400ed7678d8e95d0a4478b5f409"
   },
   "outputs": [],
   "source": [
    "# Create RNN Model\n",
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim):\n",
    "        super(RNNModel, self).__init__()\n",
    "        \n",
    "        # Number of hidden dimensions\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # Number of hidden layers\n",
    "        self.layer_dim = layer_dim\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first=True, nonlinearity='relu')\n",
    "        \n",
    "        # Readout layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "            \n",
    "        # One time step\n",
    "        out, hn = self.rnn(x, h0)\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out\n",
    "\n",
    "# batch_size, epoch and iteration\n",
    "batch_size = 100\n",
    "n_iters = 8000\n",
    "num_epochs = n_iters / (len(features_train) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "\n",
    "# Pytorch train and test sets\n",
    "train = TensorDataset(featuresTrain,targetsTrain)\n",
    "test = TensorDataset(featuresTest,targetsTest)\n",
    "\n",
    "# data loader\n",
    "train_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test, batch_size = batch_size, shuffle = False)\n",
    "    \n",
    "# Create RNN\n",
    "input_dim = 28    # input dimension\n",
    "hidden_dim = 100  # hidden layer dimension\n",
    "layer_dim = 1     # number of hidden layers\n",
    "output_dim = 10   # output dimension\n",
    "\n",
    "model = RNNModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "# Cross Entropy Loss \n",
    "error = nn.CrossEntropyLoss()\n",
    "\n",
    "# SGD Optimizer\n",
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "32786a5c-0388-412d-b6da-ee5ace604eda",
    "_uuid": "9c935ac4a1d1964b85513da422ebf60085dca0e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500  Loss: 1.4726558923721313  Accuracy: 42.726190476190474 %\n",
      "Iteration: 1000  Loss: 0.7108388543128967  Accuracy: 71.73809523809524 %\n",
      "Iteration: 1500  Loss: 0.43755194544792175  Accuracy: 85.22619047619048 %\n",
      "Iteration: 2000  Loss: 0.271086722612381  Accuracy: 90.25 %\n",
      "Iteration: 2500  Loss: 0.2235582023859024  Accuracy: 89.5 %\n",
      "Iteration: 3000  Loss: 0.09727417677640915  Accuracy: 92.66666666666667 %\n",
      "Iteration: 3500  Loss: 0.42934906482696533  Accuracy: 92.6547619047619 %\n",
      "Iteration: 4000  Loss: 0.09869173169136047  Accuracy: 94.19047619047619 %\n",
      "Iteration: 4500  Loss: 0.2372802197933197  Accuracy: 95.20238095238095 %\n",
      "Iteration: 5000  Loss: 0.10717732459306717  Accuracy: 95.19047619047619 %\n",
      "Iteration: 5500  Loss: 0.23859672248363495  Accuracy: 94.69047619047619 %\n",
      "Iteration: 6000  Loss: 0.15453924238681793  Accuracy: 96.05952380952381 %\n",
      "Iteration: 6500  Loss: 0.07914035022258759  Accuracy: 95.97619047619048 %\n",
      "Iteration: 7000  Loss: 0.12296199798583984  Accuracy: 96.27380952380952 %\n",
      "Iteration: 7500  Loss: 0.10664860904216766  Accuracy: 96.11904761904762 %\n"
     ]
    }
   ],
   "source": [
    "seq_dim = 28  \n",
    "loss_list = []\n",
    "iteration_list = []\n",
    "accuracy_list = []\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        train  = Variable(images.view(-1, seq_dim, input_dim))\n",
    "        labels = Variable(labels )\n",
    "            \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward propagation\n",
    "        outputs = model(train)\n",
    "        \n",
    "        # Calculate softmax and ross entropy loss\n",
    "        loss = error(outputs, labels)\n",
    "        \n",
    "        # Calculating gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        if count % 250 == 0:\n",
    "            # Calculate Accuracy         \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            # Iterate through test dataset\n",
    "            for images, labels in test_loader:\n",
    "                images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "                \n",
    "                # Forward propagation\n",
    "                outputs = model(images)\n",
    "                \n",
    "                # Get predictions from the maximum value\n",
    "                predicted = torch.max(outputs.data, 1)[1]\n",
    "                \n",
    "                # Total number of labels\n",
    "                total += labels.size(0)\n",
    "                \n",
    "                correct += (predicted == labels).sum()\n",
    "            \n",
    "            accuracy = 100 * correct / float(total)\n",
    "            \n",
    "            # store loss and iteration\n",
    "            loss_list.append(loss.data)\n",
    "            iteration_list.append(count)\n",
    "            accuracy_list.append(accuracy)\n",
    "            if count % 500 == 0:\n",
    "                # Print Loss\n",
    "                print('Iteration: {}  Loss: {}  Accuracy: {} %'.format(count, loss.data[0], accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "0e527a85-b600-4e40-a0ef-850537db2ab1",
    "_uuid": "0cb7130ea6e22093d6d5cb1284822b0b76b8d66c"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'iteration_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17184\\3681820617.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# visualization loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Number of iteration\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Loss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RNN: Loss vs Number of iteration\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'iteration_list' is not defined"
     ]
    }
   ],
   "source": [
    "# visualization loss \n",
    "plt.plot(iteration_list,loss_list)\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"RNN: Loss vs Number of iteration\")\n",
    "plt.show()\n",
    "\n",
    "# visualization accuracy \n",
    "plt.plot(iteration_list,accuracy_list,color = \"red\")\n",
    "plt.xlabel(\"Number of iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"RNN: Accuracy vs Number of iteration\")\n",
    "plt.savefig('graph.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eeaf09ff-e125-42ee-99fa-e231e97c4308",
    "_uuid": "0771ccf728b05cf6a5e3804e7d9bc5fa376e7ef8"
   },
   "source": [
    "### Conclusion\n",
    "In this tutorial, we learn: \n",
    "1. Basics of pytorch\n",
    "1. Linear regression with pytorch\n",
    "1. Logistic regression with pytorch\n",
    "1. Artificial neural network with with pytorch\n",
    "1. Convolutional neural network with pytorch\n",
    "    - https://www.kaggle.com/kanncaa1/pytorch-tutorial-for-deep-learning-lovers/code\n",
    "1. Recurrent neural network with pytorch\n",
    "1. Long-Short Term Memory (LSTM)\n",
    "    - https://www.kaggle.com/kanncaa1/long-short-term-memory-with-pytorch\n",
    "\n",
    "<br> If you have any question or suggest, I will be happy to hear it "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
